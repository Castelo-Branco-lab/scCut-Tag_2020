import os
import sys
import glob

config_file = os.path.dirname(workflow.basedir) + '/config/config.yaml' 
configfile: config_file

include: 'snakefile_kaya_okur'
include: 'snakefile_grosselin'
include: 'snakefile_integration'
include: 'snakefile_other_datasets'

shell.executable("/bin/bash")
#shell.prefix("source ~/.bash_profile; conda activate " + config['general']['conda_env']  + " ; ")

shell.prefix("source ~/anaconda3/etc/profile.d/conda.sh; conda activate " + config['general']['conda_env']  + " ; ")
CWD = os.getcwd()

# List of samples and antibodies
samples_list    = [x for x in config['samples']]
antibody_list   = [config['samples'][x]['Antibody'] for x in config['samples'].keys()]


# sample: antibody hash {"H3K4me3_N1":"H3K4me3"}
samples_dict    = {x: config['samples'][x]['Antibody'] for x in config['samples'].keys()}

# antibody: sample hash {'H3K4me3': ['H3K4me3_N1', 'H3K4me3_N2', 'H3K4me3_N3', 'H3K4me3_N4']}
antibody_dict = {config['samples'][x]['Antibody']: [] for x in config['samples'].keys()}
for x in config['samples'].keys():
   antibody_dict[config['samples'][x]['Antibody']].append(x)

# antibody: path to cellranger hash {"H3K27ac_M1": "/data/proj/GCB_MB/CT/CT_19_001"}
cellranger_dict = {config['samples'][x]['Antibody']: [] for x in config['samples'].keys()}
for x in config['samples'].keys():
   cellranger_dict[config['samples'][x]['Antibody']].append(config['samples'][x]['cellranger_out'])

rule all:
  input:
		# Bigwig files of raw mapped reads 
    expand("results/{sample}/bigwig/all_reads.bw",sample = samples_list),

		# MACS2 peak calling 
    expand("results/{sample}/macs/narrow/{sample}_peaks.narrowPeak",sample = samples_list),
    expand("results/{sample}/macs/broad/{sample}_peaks.broadPeak",sample = samples_list),
    expand("results/merged/{antibody}/macs/narrow/{antibody}_peaks.narrowPeak", antibody = list(set(antibody_list))),
    expand("results/merged/{antibody}/macs/for_revision/{antibody}_peaks.narrowPeak",antibody = ["H3K27me3"]),


    # MEME On merged MACS peaks
    expand(directory("results/merged/{antibody}/MEME_{width}/out_{npeaks}"),npeaks=[1000,5000,10000,25000,50000],antibody = ['Olig2','Rad21'],width=[25,50,100,150,250]),


    # Merged files accross replicates
    expand("results/{sample}/outs/fragments.tsv.gz", antibody = list(set(antibody_list)),sample=samples_list),
    expand("results/merged/{antibody}/fragments.tsv.gz", antibody = list(set(antibody_list)),sample=samples_list),  # TODO fix

    # Barcode statistics for cell selection
    expand("results/{sample}/barcode_statistics/all_barcodes.txt",sample = samples_list),
    expand("results/{sample}/barcode_statistics/peaks_barcodes_narrow.txt",sample = samples_list),
    expand("results/{sample}/barcode_statistics/peaks_barcodes_broad.txt",sample = samples_list),
    #Clustering
    expand("results/{sample}/cell_picking/{binwidth}/Seurat_object.Rds",binwidth = config['general']['clustering_window'], sample = samples_list),

    # RNA-seq clustering
    'results/Sten_RNA/clustering/01.clustering_20000cells.Rds',
    expand(directory('results/{RNA}/marker_promoters/'),RNA=["Sten_RNA","Sox10_RNA"]),
    
    'results/Sox10_RNA/clustering/GFP/01.clustering.Rds',
    'results/Sox10_RNA/clustering/GFP/RNA_expression_TPM.csv',

    # Clustering final Cut&Tag
    expand("results/{antibody}/clustering/01.clustering.Rds",antibody = list(set(antibody_list))),


    ################ Downstream analysis
    # Export for metagene
    expand(directory('results/{antibody}/clustering/markers_bed_genes/'),antibody = list(set(antibody_list))),

    # Metagene plot
    expand("results/{antibody_bw}/metagene/{antibody_bed}/metagene_plot.png",antibody_bw = list(set(antibody_list)),antibody_bed = list(set(antibody_list))),
    expand("results/{antibody_bw}/metagene/{antibody_bed}/metagene_genes.png",antibody_bw = list(set(antibody_list)),antibody_bed = list(set(antibody_list))),
    expand('results/{antibody}/metagene/metagene_{RNA}_RNA_{genes}.png',antibody = list(set(antibody_list)),RNA=["Sten","Sox10"],genes=['promoters','genes_scaled']),

    # Export bam per cluster
    directory('results/scATAC_P50/clustering/bam_per_cluster/scATAC/'),
    [expand(directory('results/{antibody}/clustering/bam_per_cluster/{sample}/'),antibody = antibody, sample = antibody_dict[antibody]) for antibody in antibody_list],
    directory('results/merged/H3K27me3/bam_per_cluster/'),

    # Peak callin bam per cluster
    [expand('results/{antibody}/clustering/bam_per_cluster/macs_broad/{cluster}/{cluster}_peaks.broadPeak',antibody = antibody, \
      cluster=list(set([os.path.basename(x).replace("_out.bam","") for x in glob.glob('results/' + antibody + '/clustering/bam_per_cluster/*/*.bam')]))) for antibody in antibody_list],
    
    # integration
    'results/Olig2/integration/integrated.Rds',
    'results/Rad21/integration/integrated.Rds',
    'results/integration/histone_3active/histone_3active_integrated.Rds',
    'results/integration/H3K4me3_RNA/H3K4me3_RNA_coembed.Rds',
    'results/integration/H3K4me3_marques/H3K4me3_marques_coembed.Rds',

    # GO terms
    'results/H3K4me3/GO_terms/GO_matrix_markers.csv',

    # scATAC
    'results/scATAC_P50/clustering/clustering_scATAC.Rds',

    # Pseudotime
    'results/H3K4me3/pseudotime/pseudotime_OLG_final.Rds',
    'results/H3K4me3/pseudotime/pseudotime_OLG_slingshot.Rds',

    # H3K4me3 spreading
    "results/H3K4me3/spreading/spreading.Rdata",
    "results/H3K4me3/spreading/breadth.Rdata",

    # Olig2 chromvar
    'results/Olig2/chromVAR/chromVAR.Rdata',

    # H3k27ac cicero
    'results/H3K27ac/cicero/cicero_image.Rdata',
    
    # Grosselin
    expand("results/other_datasets/grosselin_scChIP/{SRA}/barcodes/mapping/barcode/{SRA}_read_barcodes.txt",SRA=config['grosselin']['scChIP']),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/barcodes/mapping/genome/possorted_{SRA}.bam",SRA=config['grosselin']['scChIP']),
    directory(expand("results/other_datasets/grosselin_scChIP/{SRA}/macs/{SRA}/",SRA=config['grosselin']['scChIP'])),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/barcodes/mapping/genome/possorted_{SRA}.bw",SRA=config['grosselin']['scChIP']),
    
    
    # Kaya-Okur
    expand("results/other_datasets/kaya_okur/bed/sorted_{s}.bed.gz.tbi",s = config['kaya-okur']['samples']),
    expand("results/other_datasets/kaya_okur/bam/{s}.bam",s = config['kaya-okur']['samples']),
    expand("results/other_datasets/kaya_okur/bigwig/{s}.bw",s = config['kaya-okur']['samples']),
    
     
     
    # Fingerprint analysis
    "results/other_datasets/fingerprint_analysis/Kaya_okur_fingerprint.txt",
    "results/other_datasets/fingerprint_analysis/Grosselin_fingerprint.txt",
    "results/other_datasets/fingerprint_analysis/scCT_H3K27me3_fingerprint.txt",
    
    # FrIP analysis
    expand("results/other_datasets/frip_analysis/kaya_okur/{sample}/all_fragments.txt",sample=['K562_H3K27me3_iCell8','K562_H3K4me2_iCell8','H1_H3K27me3_iCell8']),
    expand("results/other_datasets/frip_analysis/scCT/{sample}/all_fragments.txt",antibody="H3K27me3",sample=["H3K27me3_N" + str(x) for x in [1,2,3,4]] + ["H3K27me3_cell_lines_1","H3K27me3_cell_lines_2"]),
    
    # PCA analysis
    'results/other_datasets/PCA/PCA_table_cell_lines.npz',
    'results/other_datasets/PCA/PCA_table_brain.npz',
    

################## PREPROCESSING
rule bam_to_bw:
    input:
        lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam'
    output:
        "results/{sample}/bigwig/all_reads.bw"
    threads: 8
    shell:
        "bamCoverage -b {input} -o {output} -p {threads} --minMappingQuality 5 "
        " --binSize 100 --centerReads --smoothLength 500 --normalizeUsing RPKM --ignoreDuplicates"

rule run_macs_narrow:
    input:
       lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam',
    output:
        "results/{sample}/macs/narrow/{sample}_peaks.narrowPeak"
    params:
        macs_outdir = "results/{sample}/macs/narrow"
    shell:
        "macs2 callpeak -t {input} -g mm -f BAMPE -n {wildcards.sample} "
        "--outdir {params.macs_outdir} -q 0.05 -B --SPMR --keep-dup=1 2>&1 "
        

rule run_macs_broad:
    input:
        lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam'
    output:
        "results/{sample}/macs/broad/{sample}_peaks.broadPeak"
    params:
        macs_outdir = "results/{sample}/macs/broad"
    shell:
        "macs2 callpeak -t {input} -g mm -f BAMPE -n {wildcards.sample} "
        "--outdir {params.macs_outdir} -q 0.05 -B --SPMR --keep-dup=1 --broad-cutoff=0.1 --broad 2>&1 "

rule macs_merged:
  input:
    lambda wildcards: [x + '/outs/possorted_bam.bam' for x in cellranger_dict[wildcards.antibody] ]
  output:
    "results/merged/{antibody}/macs/narrow/{antibody}_peaks.narrowPeak",
    "results/merged/{antibody}/macs/broad/{antibody}_peaks.broadPeak",
    "results/merged/{antibody}/macs/narrow/{antibody}_summits.bed",
  params:
    out_narrow   = "results/merged/{antibody}/macs/narrow/",
    out_broad    = "results/merged/{antibody}/macs/broad/",
  shell:
    "macs2 callpeak -t {input} -g mm -f BAMPE -n {wildcards.antibody} --outdir {params.out_narrow} -q 0.05 -B --SPMR --keep-dup=1 2>&1 && "
    "macs2 callpeak -t {input} -g mm -f BAMPE -n {wildcards.antibody} --outdir {params.out_broad} --broad-cutoff=0.1 --broad -q 0.05 -B --SPMR --keep-dup=1 2>&1 "

rule macs_merged_for_revision:
  input:
    lambda wildcards: [x + '/outs/possorted_bam.bam' for x in cellranger_dict[wildcards.antibody] ]
  output:
    "results/merged/{antibody}/macs/for_revision/{antibody}_peaks.narrowPeak",
  params:
    out_revision = "results/merged/{antibody}/macs/for_revision/"
  shell:
    "macs2 callpeak -t {input} -g mm -f BAMPE -n {wildcards.antibody} --outdir {params.out_revision} --nomodel  --max-gap 2500 --nolambda " # --slocal 1000000 --llocal 1000000 "

rule barcode_statistics_peaks:
    input:
        bam          = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam',
        peaks_broad  = "results/{sample}/macs/broad/{sample}_peaks.broadPeak",
        peaks_narrow = "results/{sample}/macs/narrow/{sample}_peaks.narrowPeak"
    output:
        narrow = "results/{sample}/barcode_statistics/peaks_barcodes_narrow.txt",
        broad  = "results/{sample}/barcode_statistics/peaks_barcodes_broad.txt"
    params:
        scripts    = os.path.dirname(workflow.basedir) + '/scripts',
    shell:
      #  "set +o pipefail; "
        "bedtools intersect -abam {input.bam} -b {input.peaks_broad} -u | samtools view -f2 | "
        " awk -f {params.scripts}/get_cell_barcode.awk | sed 's/CB:Z://g' | sort | uniq -c > {output.broad} && [[ -s {output.broad} ]] ; "
        " bedtools intersect -abam {input.bam} -b {input.peaks_narrow} -u | samtools view -f2 | "
        " awk -f {params.scripts}/get_cell_barcode.awk | sed 's/CB:Z://g' | sort | uniq -c > {output.narrow} && [[ -s {output.narrow} ]] ;"

rule barcode_statistics_all:
  input:
     bam       = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam',
  output:
    all_bcd    = "results/{sample}/barcode_statistics/all_barcodes.txt"
  params:
    scripts    = os.path.dirname(workflow.basedir) + '/scripts',
  shell:
    #" set +o pipefail; "
    " samtools view -f2 {input.bam}| "
    " awk -f {params.scripts}/get_cell_barcode.awk | sed 's/CB:Z://g' | sort | uniq -c > {output.all_bcd} && [[ -s {output.all_bcd} ]] "

rule merge_bam:
    input:
        lambda wildcards: [x + '/outs/possorted_bam.bam' for x in cellranger_dict[wildcards.antibody] ]
    output:
        "results/merged/{antibody}/possorted_bam.bam"
    threads: 8
    shell:
        "samtools merge --threads {threads} {output} {input} && samtools index {output}" 

rule merge_fragments:
    input:
        lambda wildcards: ['results/' + x + '/outs/fragments.tsv.gz' for x in antibody_dict[wildcards.antibody] ]
    output:
        "results/merged/{antibody}/fragments.tsv.gz"
    shell:
        "gunzip -c {input} | sort -k1,1 -k2,2n | bgzip  > {output} && "
        "tabix -p bed {output}" 


rule add_barcode_fragments:
    input:
        fragments = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/fragments.tsv.gz'
    output:
        fragments = "results/{sample}/outs/fragments.tsv.gz",
        index     = "results/{sample}/outs/fragments.tsv.gz.tbi"
    params:
        script         = os.path.dirname(workflow.basedir) + '/scripts/add_sample_to_fragments.py',
    shell:
      #  "set +o pipefail; "
        "python3 {params.script} {input.fragments} {wildcards.sample} | bgzip > {output.fragments}; "
        "tabix -p bed {output.fragments}"

rule download_blacklist:
  output:
    "results/mm10.blacklist.bed.gz"
  params:
    out_dir = 'results/'
  shell:
    "wget -P {params.out_dir} http://mitra.stanford.edu/kundaje/akundaje/release/blacklists/mm10-mouse/mm10.blacklist.bed.gz"

# Fingerprint analysis
# Merge per cluster
rule merge_bam_per_cluster:
  input:
    directory("results/{antibody}/clustering/bam_per_cluster/")
  output:
    directory('results/merged/{antibody}/bam_per_cluster/')
  params:
    bam_per_cluster_dir =  "results/{antibody}/clustering/bam_per_cluster/"
  threads:16
  shell:
    """
    clusters=$(ls {params.bam_per_cluster_dir}/*/*.bam | while read line; do basename $line| sed 's/_out.bam//g'; done | sort | uniq); 
    for cluster in $clusters; do  
      infiles=$(find {params.bam_per_cluster_dir} -name $cluster"*.bam") ; 
      samtools merge -@ {threads} "{output}"$cluster"_merged.bam" $infiles; 
      samtools index {output}
    done
    """

rule plot_fingerprint_scCT:
  input:
    merged_bam        = "results/merged/{antibody}/possorted_bam.bam",
    per_replicate_bam = expand("{cellranger}/outs/possorted_bam.bam",cellranger = [config['samples'][x]['cellranger_out'] for x in config['samples'] if config['samples'][x]['Antibody'] == "H3K27me3"]),
    per_cluster_bam   = directory('results/merged/{antibody}/bam_per_cluster/'),
  output:
    "results/other_datasets/fingerprint_analysis/scCT_{antibody}_fingerprint.txt"
  threads: 16
  params:
    per_cluster_bam = 'results/merged/H3K27me3/bam_per_cluster/*.bam'
  shell:
    """
      plotFingerprint --ignoreDuplicates --outRawCounts {output} -b {input.merged_bam} {input.per_replicate_bam} {params.per_cluster_bam} -p 16
    """

# FrIP analysis

rule call_peaks_scCT_FrIP:
  input:
    #bam="results/{sample}/outs/fragments.tsv.gz" # Cellranger fragments.tsv output
    bam = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam'
  output:
    directory("results/other_datasets/frip_analysis/scCT/{sample}/macs/")
  params:
    outdir = directory("results/other_datasets/frip_analysis/scCT/{sample}/macs/"),
    name   = "{sample}"
  shell:
    "macs2 callpeak -t {input.bam} -g mm -f BAM --outdir {params.outdir} --nomodel -n {params.name} --max-gap 2500 --nolambda --slocal 1000000 --llocal 1000000"

rule intersect_fragments_with_peaks:
  input:
    peaks=directory("results/other_datasets/frip_analysis/scCT/{sample}/macs/"),
    fragments="results/{sample}/outs/fragments.tsv.gz",
  output:
    all_fragments  = "results/other_datasets/frip_analysis/scCT/{sample}/all_fragments.txt",
    peak_fragments = "results/other_datasets/frip_analysis/scCT/{sample}/peak_fragments.txt",
  params:
      sample = "{sample}"
  shell:
    """
    zcat {input.fragments} | cut -f4 | sort | uniq -c > {output.all_fragments} 
    bedtools intersect -a {input.fragments} -b {input.peaks}{params.sample}_peaks.narrowPeak -wa | cut -f4 | sort | uniq -c > {output.peak_fragments}
    """

rule PCA:
  input:
    scCT_bigwig        = directory("results/H3K27me3/clustering/bigwig/"),
    markers_brain      = directory('results/H3K27me3/clustering/markers_bed/'),
    markers_cell_lines = directory('results/H3K27me3_cell_lines/clustering/markers_bed/'),
    cell_lines         = directory("results/H3K27me3_cell_lines/clustering/bigwig/"),
    bonev_CN           = "results/other_datasets/bonev/GSE96107_CN_H3K27me3.bw",
    matsuda_MGL        = "results/other_datasets/matsuda/GSM2800523_Microglia_H3K27me3_ChIP-seq.bw",
    OPCs_GCB           = "/data/proj/GCB_MB/cut_tag_GCB_lab/H3K27me3_OPCs/P13556_1026_dedup.bw",     # Deposit to GEO and fix link
    Oli_neu_GCB        = "/data/proj/GCB_MB/cut_tag_GCB_lab/H3K27me3_olineu/P13556_1015_dedup.bw",   # Deposit to GEO and fix link
    mESC_bigwig_1      = 'results/other_datasets/mESC_ENCODE/bigwig/mESC_rep1.bw',
    mESC_bigwig_2      = 'results/other_datasets/mESC_ENCODE/bigwig/mESC_rep2.bw',
    cells_3T3_rep1     = 'results/other_datasets/3T3_cells/bigwig/SRR9889940.bw',
    cells_3T3_rep2     = 'results/other_datasets/3T3_cells/bigwig/SRR9889941.bw',
  output:
#    markers='results/other_datasets/PCA/markers_all.bed',
    table_cell_lines   = 'results/other_datasets/PCA/PCA_table_cell_lines.npz',
    table_brain        = 'results/other_datasets/PCA/PCA_table_brain.npz',
    markers_cell_lines = 'results/other_datasets/PCA/markers_cell_lines.bed',
    markers_brain      = 'results/other_datasets/PCA/markers_brain.bed',
  shell:
    """
    ls {input.markers_cell_lines}*.bed | while read line; do head -100 $line >> {output.markers_cell_lines}; done 
    ls {input.markers_brain}*.bed | while read line; do head -100 $line >> {output.markers_brain}; done 
    multiBigwigSummary BED-file -b {input.cell_lines}*.bw {input.Oli_neu_GCB} {input.mESC_bigwig_1} {input.mESC_bigwig_2} {input.cells_3T3_rep1} {input.cells_3T3_rep2} -o {output.table_cell_lines} --BED {output.markers_cell_lines} 
    multiBigwigSummary BED-file -b {input.scCT_bigwig}*.bw {input.bonev_CN} {input.matsuda_MGL} {input.OPCs_GCB} -o {output.table_brain} --BED {output.markers_brain} 
    """
    # ls {input.markers_brain}*.bed {input.markers_lines}*.bed | grep -v OEC | while read line; do cat $line >> {output.markers}; done
    # multiBigwigSummary BED-file -b {input.scCT_bigwig}*.bw {input.cell_lines}*.bw {input.bonev_CN} {input.matsuda_MGL} {input.OPCs_GCB} {input.Oli_neu_GCB} -o {output.table} --BED {output.markers}
    
    
    



# Motif search
rule motif_search:
  input:
      peaks     = "results/merged/{antibody}/macs/narrow/{antibody}_summits.bed",
      blacklist = "results/mm10.blacklist.bed.gz"
  output:
      meme_out           = directory("results/merged/{antibody}/MEME_{width}/out_{npeaks}"),
  params:
      summits_filtered   = "results/merged/{antibody}/MEME_{width}/summits_filtered_{npeaks}.bed",
      top_summits        = "results/merged/{antibody}/MEME_{width}/top_summits_{npeaks}.bed",
      top_summits_padded = "results/merged/{antibody}/MEME_{width}/top_summits_padded_{npeaks}.bed",
      top_summits_fa     = "results/merged/{antibody}/MEME_{width}/top_summits_{npeaks}.fa",
      genome_fa          = config['db']['genome_fa'],
      npeaks             = "{npeaks}",
      #out                = "results/merged/{antibody}/MEME_{width}/out_{npeaks}",
  shell:
#      "set +o pipefail;"
      "cat {input.peaks} | grep -v -e 'chrM' | sort-bed - | bedops -n 1 - {input.blacklist} > {params.summits_filtered};"
      "sort -k5gr {params.summits_filtered} | head -{params.npeaks} | sort-bed - > {params.top_summits};"
      "bedops --range {wildcards.width} -u {params.top_summits} > {params.top_summits_padded};"
      "bedtools getfasta -fi {params.genome_fa} -bed {params.top_summits_padded} -fo {params.top_summits_fa};"
      "conda activate meme; " # MEME=5.1.1 env
      "meme-chip -oc {output.meme_out} -dreme-m 10 -meme-nmotifs 10 {params.top_summits_fa};"



####### CELLS SELECTION
rule cell_selection:
  input:
      all_bcd    = "results/{sample}/barcode_statistics/all_barcodes.txt",
      bcd_narrow = "results/{sample}/barcode_statistics/peaks_barcodes_narrow.txt",
      bcd_broad  = "results/{sample}/barcode_statistics/peaks_barcodes_broad.txt",
      peaks      = "results/{sample}/macs/broad/{sample}_peaks.broadPeak",
      metadata   = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/singlecell.csv',
      fragments  = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/fragments.tsv.gz',
      
      
  output:
      "results/{sample}/cell_picking/{binwidth}/cells_10x.png",
      "results/{sample}/cell_picking/{binwidth}/cells_picked.png",
      "results/{sample}/cell_picking/{binwidth}/cells_picked.bw",
      "results/{sample}/cell_picking/{binwidth}/cells_not_picked.bw",
      "results/{sample}/cell_picking/{binwidth}/Seurat_object.Rds",
  params:
      script         = os.path.dirname(workflow.basedir) + '/scripts/R/process_cellranger.R',
      out_prefix     = "results/{sample}/cell_picking/{binwidth}/", 
      config_file    = config_file,
  shell:
      "Rscript {params.script}  --sample {wildcards.sample} --config {params.config_file} --out_prefix {params.out_prefix} --window {wildcards.binwidth}"

########### FINAL TWEAKED CLUSTERING
rule clustering_final:
  input:
    lambda wildcards: expand("results/{sample}/cell_picking/5000/Seurat_object.Rds", sample = [x for x in samples_dict if samples_dict[x] == wildcards.antibody]),
    notebook       = os.path.dirname(workflow.basedir) + "/notebooks/{antibody}/{antibody}_clustering_merge.Rmd",
    RNAmarkers     = 'results/Sten_RNA/clustering/sten_RNA_markers.csv',
    GFPmarkers     ='results/Sox10_RNA/clustering/GFP/markers.csv',
    # peaks_narrow   = 'results/merged/{antibody}/macs/narrow/{antibody}_peaks.narrowPeak', # TODO: Fix atac conflict
    # peaks_broad    = 'results/merged/{antibody}/macs/broad/{antibody}_peaks.broadPeak' # TODO: Fix atac conflict
    # TODO: Olig2 depends on H3K27ac, write lambda function for that 
  output:
    seurat  = "results/{antibody}/clustering/01.clustering.Rds",
    report  = "results/{antibody}/clustering/01.clustering.html",
    markers = "results/{antibody}/clustering/markers.csv",
    bigwig  = directory("results/{antibody}/clustering/bigwig/"),
    bed     = directory("results/{antibody}/clustering/markers_bed/"),
    table   = "results/{antibody}/clustering/bam_per_cluster/cluster_barcode_table.csv",
    
  params:
    config         = config_file,
    out_prefix     = CWD + '/results/',
    report         = CWD + '/results/{antibody}/clustering/01.clustering.html',
  shell:
    " Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(config='{params.config}',out_prefix = '{params.out_prefix}',antibody = '{wildcards.antibody}'))\" "

# 

###########################################################
################### DOWNSTREAM ANALYSIS ###################
###########################################################
rule call_peaks_bam_per_cluster:
  input:
    lambda wildcards: expand(directory('results/{antibody}/clustering/bam_per_cluster/{sample}/'),sample = antibody_dict[wildcards.antibody],antibody = wildcards.antibody),
  output:
   'results/{antibody}/clustering/bam_per_cluster/macs_broad/{cluster}/{cluster}_peaks.broadPeak',
  params:
    bam_files = lambda wildcards: expand(directory('results/{antibody}/clustering/bam_per_cluster/{sample}/{cluster}_out.bam'),sample = antibody_dict[wildcards.antibody],antibody = wildcards.antibody,cluster = wildcards.cluster),
    outdir    = 'results/{antibody}/clustering/bam_per_cluster/macs_broad/{cluster}'
  shell:
    "macs2 callpeak -t {params.bam_files}  \
  -n {wildcards.cluster} \
  -f BAMPE \
  -g mm \
  --qvalue 1e-10 \
  --outdir {params.outdir} \
  --broad \
  --bdg \
  --max-gap 1000 \
  --min-length 500 \
  --broad-cutoff 0.001 \
  --llocal 1000000 \
  --slocal 0"





rule markers_to_gene:
  input:
    markers  = 'results/{antibody}/clustering/markers.csv'
  output:
    directory('results/{antibody}/clustering/markers_bed_genes/')
  params:
    script = os.path.dirname(workflow.basedir) + "/scripts/R/markers_to_bed.R"
  shell:
    "Rscript {params.script} {input.markers} {output}"


######## METAGENE PLOTS
rule metagene:
  input:
    bw       = directory("results/{antibody1}/clustering/bigwig/"),
    bed      = directory("results/{antibody2}/clustering/markers_bed/"),
    bed_gene = directory("results/{antibody2}/clustering/markers_bed_genes/"),
  output:
    matrix1 = "results/{antibody1}/metagene/{antibody2}/metagene_plot.txt.gz",
    png1    = "results/{antibody1}/metagene/{antibody2}/metagene_plot.png",
    matrix2 = "results/{antibody1}/metagene/{antibody2}/metagene_genes.txt.gz",
    png2    = "results/{antibody1}/metagene/{antibody2}/metagene_genes.png",
  threads: 8
  shell:
    "computeMatrix reference-point -S {input.bw}*.bw -R {input.bed}*.bed -o {output.matrix1} -a 10000 -b 10000 -p {threads} &&"
    "plotHeatmap -m {output.matrix1} -o {output.png1} --sortRegions descend --refPointLabel peak --averageTypeSummaryPlot sum --colorList white,darkred --heatmapWidth 10  --heatmapHeight 80; "
    
    "computeMatrix scale-regions -S {input.bw}*.bw -R {input.bed_gene}*.bed -o {output.matrix2} -a 2000 -b 2000 -p {threads} &&"
    "plotHeatmap -m {output.matrix2} -o {output.png2} --sortRegions descend --refPointLabel peak --averageTypeSummaryPlot sum --colorList white,darkred --heatmapWidth 10  --heatmapHeight 80; "



rule metagene_RNA_promoters:
  input:
    promoters  = directory('results/{RNA}/marker_promoters/'),
    bigwig     = directory('results/{antibody}/clustering/bigwig/'),
  output:
    matrix   = 'results/{antibody}/metagene/metagene_{RNA}_promoters.txt.gz',
    png      = 'results/{antibody}/metagene/metagene_{RNA}_promoters.png',
    matrix2  = 'results/{antibody}/metagene/metagene_{RNA}_genes_scaled.txt.gz',
    png2     = 'results/{antibody}/metagene/metagene_{RNA}_genes_scaled.png',
  threads: 8
  shell:
    "computeMatrix reference-point -S {input.bigwig}*.bw -R {input.promoters}*_promoters.bed -o {output.matrix} -a 10000 -b 10000 -p {threads} && "
    "plotHeatmap -m {output.matrix} -o {output.png} --sortRegions descend --refPointLabel promoter --averageTypeSummaryPlot sum --colorList white,darkgreen --heatmapWidth 10  --heatmapHeight 80; "
    "computeMatrix scale-regions -S {input.bigwig}*.bw -R {input.promoters}*_genes.bed -o {output.matrix2} -a 2000 -b 2000 -p {threads} && "
    "plotHeatmap -m {output.matrix2} -o {output.png2} --sortRegions descend --refPointLabel promoter --averageTypeSummaryPlot sum --colorList white,darkgreen --heatmapWidth 10  --heatmapHeight 80; "

rule export_bam:
  input:
    bam   = lambda wildcards: 'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_possorted_bam.bam' if wildcards.antibody == 'scATAC_P50' else (config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam'),
    table = 'results/{antibody}/clustering/bam_per_cluster/cluster_barcode_table.csv',
  output:
    #sam_files = directory('results/bam_per_cluster/{sample}/'),
    sam_files  = directory('results/{antibody}/clustering/bam_per_cluster/{sample}/'),
  params:
    filter_bam          =   os.path.dirname(workflow.basedir) + "/scripts/filter_bam_by_barcode.py",
    sample              =   lambda wildcards: "NA" if wildcards.antibody == "scATAC_P50" else wildcards.sample,
  shell:
    "python3 {params.filter_bam} {input.bam} {input.table} {params.sample} {output.sam_files}; "

###### Integration 3 active marks
rule integration_active:
  input:
    "results/H3K4me3/clustering/01.clustering.Rds",
    "results/H3K27ac/clustering/01.clustering.Rds",
    "results/H3K36me3/clustering/01.clustering.Rds",
    notebook = os.path.dirname(workflow.basedir) + "/notebooks/integration/integration_3active.Rmd",
  output:
    "results/integration/histone_3active/histone_3active_integrated.Rds",
  params:
    report     = CWD + "/results/integration/histone_3active/Histone_3active_integrated.html",
    out_prefix = CWD + "/results/"
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\" "
    
######## Olig2 and Rad21

rule integration_olig2_rad21:
  input:
    'results/{antibody}/clustering/01.clustering.Rds',
    'results/H3K27ac/clustering/01.clustering.Rds',
    notebook = os.path.dirname(workflow.basedir) + "/notebooks/{antibody}/Integration_H3K27ac.Rmd",
  output:
    'results/{antibody}/integration/integrated.Rds',
    directory('results/{antibody}/integration/bigwig/')
  params:
    report         = CWD + '/results/{antibody}/integration/integrated.html',
    out_prefix     = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file='{params.report}',params=list(out_prefix='{params.out_prefix}')) \""


###### H3K4me3 GO analysis
rule GO_H3K4me3:
  input:
    seurat  = "results/H3K4me3/clustering/01.clustering.Rds",
    markers = "results/H3K4me3/clustering/markers.csv",
  output:
    'results/H3K4me3/GO_terms/GO_matrix_markers.csv',
  params:
    notebook   = os.path.dirname(workflow.basedir) + "/notebooks/H3K4me3/GO_analysis.Rmd",
    report     = CWD + '/results/H3K4me3/GO_terms/GO_analysis.html',
    out_prefix = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{params.notebook}',output_file='{params.report}',params=list(out_prefix='{params.out_prefix}')) \""


####### H3K4me4 RNA integration
rule H3K4me3_Sten_integrate:
  input:
    'results/H3K4me3/clustering/01.clustering.Rds',
    'results/Sten_RNA/clustering/01.clustering_20000cells.Rds',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/integration/integration_H3K4me3_RNA.Rmd',
  output:
    'results/integration/H3K4me3_RNA/H3K4me3_RNA_coembed.Rds'
  params:
    report = CWD + '/results/integration/H3K4me3_RNA/H3K4me3_RNA_coembed.html',
    out_prefix = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""

###### H3K4me3 pseudotime
rule pseudotime:
  input:
    seurat   = 'results/H3K4me3/clustering/01.clustering.Rds',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/H3K4me3/pseudotime.Rmd',
  output:
    'results/H3K4me3/pseudotime/pseudotime_OLG_final.Rds',
    'results/H3K4me3/pseudotime/pseudotime_OLG_slingshot.Rds'
  params:
    out_prefix = CWD + '/results/',
    report     = CWD + '/results/H3K4me3/pseudotime/pseudotime_final.html',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""


######### H3K4me3 spreading

rule spreading_H3K4me3:
  input:
    "results/H3K4me3/clustering/01.clustering.Rds",
    "results/H3K4me3/pseudotime/pseudotime_OLG_final.Rds",
    "results/H3K4me3/pseudotime/pseudotime_OLG_slingshot.Rds",
    "results/merged/H3K4me3/fragments.tsv.gz",
    "results/Sox10_RNA/clustering/GFP/markers.csv",
    "results/merged/H3K4me3/macs/broad/H3K4me3_peaks.broadPeak",
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/H3K4me3/spreading.Rmd',
  output:
    "results/H3K4me3/spreading/spreading.Rdata",
  params:
    out_prefix = CWD + "/results/",
    report     = CWD + "/results/H3K4me3/spreading/spreading.html",
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""

rule breadth_H3K4me3:
  input:
    # Cellranger peaks.bed file
    lambda wildcards: ['results/' + x + '/outs/fragments.tsv.gz' for x in antibody_dict[wildcards.antibody] ],
    'results/Sox10_RNA/clustering/GFP/markers.csv',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/H3K4me3/breadth.Rmd',
  output:
    "results/{antibody}/spreading/breadth.Rdata",
  params:
    report = CWD + "/results/{antibody}/spreading/breadth.html",
    out_prefix = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""    


# Olig2 chromvar
rule chromvar:
  input:
    'results/{antibody}/clustering/01.clustering.Rds',
    'results/merged/{antibody}/fragments.tsv.gz',
    'results/merged/{antibody}/macs/narrow/{antibody}_summits.bed',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/{antibody}/chromVAR.Rmd',
  output:
    'results/{antibody}/chromVAR/chromVAR.Rdata',
  params:
    report      = CWD + '/results/{antibody}/chromVAR/chromVAR.html',
    out_prefix  = CWD + '/results/',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""    


# H3K27ac cicero

rule cicero:
  input:
    'results/{antibody}/clustering/01.clustering.Rds',
#    directory('results/{antibody}/clustering/bam_per_cluster/H3K27ac_N1/'), # Fix this ?
#    directory('results/{antibody}/clustering/bam_per_cluster/H3K27ac_N2/'), # Fix this ?
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/{antibody}/Cicero.Rmd',
  output:
    'results/{antibody}/cicero/cicero_image.Rdata',
    directory('results/{antibody}/cicero/loops/')
  params:
    report      = CWD + '/results/{antibody}/cicero/cicero.html',
    out_prefix  = CWD + '/results/',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""    





#############################################
################# scRNA-seq #################
#############################################

# Mouse brain atlas SL lab


rule Sten_download:
  output:
    loom = 'results/Sten_RNA/l5_all.loom'
  params:
    download_folder = CWD + '/results/Sten_RNA/',
    loom_url        = config['RNA_seq']['Sten_RNA']['loom_source']
  shell:
    'wget {params.loom_url}  -P {params.download_folder}'

rule Sten_RNA_clustering:
  input:
    config['RNA_seq']['Sten_RNA']['loom_file']
  output:
    #report      = 'results/Sten_RNA/01.clustering.html',
    R_object    = 'results/Sten_RNA/clustering/01.clustering_20000cells.Rds',
    markers     = 'results/Sten_RNA/clustering/sten_RNA_markers.csv'
  params:
    config      = config_file,
    notebook    = os.path.dirname(workflow.basedir) + '/notebooks/Sten_RNA/01.clustering.Rmd',
    out_prefix  = CWD + '/results/',
    report      = CWD + '/results/Sten_RNA/01.clustering.html',

  shell:
    "Rscript -e \"rmarkdown::render(input='{params.notebook}',output_file = '{params.report}', params=list(config='{params.config}',out_prefix = '{params.out_prefix}'))\""

rule export_marker_promoters_Sten:
  input:
    markers     = 'results/Sten_RNA/clustering/sten_RNA_markers.csv',
    notebook   = os.path.dirname(workflow.basedir) + '/notebooks/Sten_RNA/RNA_marker_promoters_export.Rmd',
  output:
    directory('results/Sten_RNA/marker_promoters/'),
  params:
    report     = CWD + '/results/Sten_RNA/RNA_marker_promoters_export.html',
    out_prefix = CWD + '/results/',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""

######## Sox10 RNA

rule Sox10_RNA_clustering:
  input:
    rep1 = config['RNA_seq']['Sox10_RNA']['replicate1'],
    rep2 = config['RNA_seq']['Sox10_RNA']['replicate2']
  output:
    # report       = 'results/Sox10_RNA/01.clustering.html',
    R_object_all = 'results/Sox10_RNA/clustering/all_cells/01.clustering.Rds',
    markers_all  = 'results/Sox10_RNA/clustering/all_cells/markers.csv',
    heatmap_all  = 'results/Sox10_RNA/clustering/all_cells/heatmap.png',
    R_object_GFP = 'results/Sox10_RNA/clustering/GFP/01.clustering.Rds',
    markers_GFP  = 'results/Sox10_RNA/clustering/GFP/markers.csv',
    heatmap_GFP  = 'results/Sox10_RNA/clustering/GFP/heatmap.png',

  params: # Absolute paths here
    config       = config_file,
    notebook     = os.path.dirname(workflow.basedir) + '/notebooks/Sox10_RNA/01.clustering.Rmd',
    out_prefix   = CWD + '/results/Sox10_RNA/clustering/',
    report       = CWD + '/results/Sox10_RNA/01.clustering.html',


  shell:
    "Rscript -e \"rmarkdown::render(input='{params.notebook}',output_file = '{params.report}', params=list(config='{params.config}',out_prefix = '{params.out_prefix}'))\""

rule Sox10_RNA_TPM:
  input:
    'results/Sox10_RNA/clustering/GFP/01.clustering.Rds'
  output:
    'results/Sox10_RNA/clustering/GFP/RNA_expression_TPM.csv'
  params:
    script = os.path.dirname(workflow.basedir) + "/scripts/R/Seurat_TPM.R",
  shell:
    'Rscript {params.script} {input} {output}'

rule export_marker_promoters_Sox10:
  input:
    markers     = 'results/Sox10_RNA/clustering/GFP/markers.csv',
    notebook    = os.path.dirname(workflow.basedir) + '/notebooks/Sox10_RNA/RNA_marker_promoters_export.Rmd',
  output:
    directory('results/Sox10_RNA/marker_promoters/'),
  params:
    report     = CWD + '/results/Sox10_RNA/RNA_marker_promoters_export.html',
    out_prefix = CWD + '/results/',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""

# Integration Sox10 - SL scRNA-seq

rule integrate_scRNA_seq:
  input:
    'results/Sox10_RNA/clustering/GFP/01.clustering.Rds',
    'results/Sten_RNA/clustering/01.clustering_20000cells.Rds',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/Sox10_RNA/integration_2RNA.Rmd',
  output:
    'results/"Sox10_RNA/integration/scRNA_integrated.Rds'
  params:
    report     = 'results/"Sox10_RNA/integration/scRNA_integrated.html',
    out_prefix =  CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""

############### Marques RNA

rule download_marques:
  output:
    metadata = 'results/marques_RNA/data/Marques2016annotation.rds',
    matrix   = 'results/marques_RNA/data/GSE75330_Marques_et_al_mol_counts2.tab.gz',
  params:
    url    = config['RNA_seq']['Marques_RNA']['url'],
    annot  = os.path.dirname(workflow.basedir) + '/data/Marques2016annotation.rds',
    outdir = 'results/marques_RNA/data/'
  shell:
    "wget -P {params.outdir} {params.url}; "
    "cp {params.annot} {params.outdir}"

rule marques_proccess_and_integrate:
  input:
    'results/marques_RNA/data/GSE75330_Marques_et_al_mol_counts2.tab.gz',
    'results/marques_RNA/data/Marques2016annotation.rds',
    notebook   = os.path.dirname(workflow.basedir) + '/notebooks/integration/integration_H3K4me3_marques.Rmd',
  output:
    'results/integration/H3K4me3_marques/H3K4me3_marques_coembed.Rds',
    'results/marques_RNA/clustering/01.clustering.Rds',
    "results/marques_RNA/clustering/markers_merged_clusters.csv",
    "results/marques_RNA/clustering/markers.csv",
  params:
    report     = CWD + '/results/integration/H3K4me3_marques/H3K4me3_marques_coembed.html',
    out_prefix = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""



################ scATAC-seq

rule download_ATAC:  
  output:
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_filtered_peak_bc_matrix.h5',
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_singlecell.csv',
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_fragments.tsv.gz',
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_possorted_bam.bam'
  params:
    url = " ".join(list(config['ATAC_seq']['P50']['url'].values()))
  shell:
    'wget -P {output} {params.url}'

rule analyze_ATAC:
  input:
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_filtered_peak_bc_matrix.h5',
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_singlecell.csv',
    'results/scATAC_P50/data/atac_v1_adult_brain_fresh_5k_fragments.tsv.gz',
    'results/Sten_RNA/clustering/sten_RNA_markers.csv',
  output:
    seurat_object = 'results/scATAC_P50/clustering/clustering_scATAC.Rds',
    bigwig        = directory('results/scATAC_P50/clustering/bigwig/'),
    barcode_table = 'results/scATAC_P50/clustering/bam_per_cluster/cluster_barcode_table.csv',
  params:
    notebook      = os.path.dirname(workflow.basedir) + '/notebooks/scATAC/01.clustering.Rmd',
    out_prefix    = CWD + '/results/',
    report        = CWD + '/results/scATAC_P50/clustering/01.clustering.html',
  shell:
    "Rscript -e \"rmarkdown::render(input='{params.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""























