import os
import sys
import glob

include: 'preflight'
include: 'snakefile_preprocess'
include: 'snakefile_clustering'
include: 'snakefile_kaya_okur'
include: 'snakefile_grosselin'
include: 'snakefile_integration'
include: 'snakefile_other_datasets'
include: 'snakefile_figures'
include: 'snakefile_scRNA-seq'
include: 'snakefile_downscale'
# include: 'snakefile_downstream'

configfile: os.path.dirname(workflow.basedir) + '/config/config.yaml'

rule all:
  input:
		# Bigwig files of raw mapped reads 
    expand("results/{sample}/bigwig/all_reads.bw",sample = samples_dict.keys()),

		# MACS2 peak calling 
    expand("results/{sample}/macs/narrow/{sample}_peaks.narrowPeak",sample = samples_dict.keys()),
    expand("results/{sample}/macs/broad/{sample}_peaks.broadPeak",sample = samples_dict.keys()),
    expand("results/merged/{antibody}/macs/narrow/{antibody}_peaks.narrowPeak", antibody = antibody_dict.keys()),
    expand("results/merged/{antibody}/macs/for_revision/{antibody}_peaks.narrowPeak",antibody = ["H3K27me3"]),


    # MEME On merged MACS peaks
    expand("results/merged/{antibody}/MEME_{width}/out_{npeaks}",npeaks=[1000,5000,10000,25000,50000],antibody = ['Olig2','Rad21'],width=[25,50,100,150,250]),


    # Merged files accross replicates
    expand("results/{sample}/outs/fragments.tsv.gz", antibody = antibody_dict.keys(),sample=samples_dict.keys()),
    expand("results/merged/{antibody}/fragments.tsv.gz", antibody = antibody_dict.keys(),sample=samples_dict.keys()),  # TODO fix

    # Barcode statistics for cell selection
    expand("results/{sample}/barcode_statistics/all_barcodes.txt",sample = samples_dict.keys()),
    expand("results/{sample}/barcode_statistics/peaks_barcodes_narrow.txt",sample = samples_dict.keys()),
    expand("results/{sample}/barcode_statistics/peaks_barcodes_broad.txt",sample = samples_dict.keys()),
    
    # Create Seurat objects
    expand("results/{sample}/seurat/bin_{binwidth}/Seurat_object.Rds", sample = samples_dict.keys(),binwidth = config['general']['clustering_window']),
    
    # Merge and run clustering together
    expand("results/{antibody}/clustering/01.clustering.Rds",antibody = antibody_dict.keys()),


    ################ Downstream analysis
    # Export for metagene
    expand('results/{antibody}/clustering/markers_bed_genes/',antibody = antibody_dict.keys()),

    # Metagene plot
    expand("results/{antibody_bw}/metagene/{antibody_bed}/metagene_plot.png",antibody_bw = antibody_dict.keys(),antibody_bed = antibody_dict.keys()),
    expand("results/{antibody_bw}/metagene/{antibody_bed}/metagene_genes.png",antibody_bw = antibody_dict.keys(),antibody_bed = antibody_dict.keys()),
    expand('results/{antibody}/metagene/metagene_{RNA}_RNA_{genes}.png',antibody = antibody_dict.keys(),RNA=["Sten","Sox10"],genes=['promoters','genes_scaled']),

    # Export bam per cluster
    'results/scATAC_P50/clustering/bam_per_cluster/scATAC/',
    [expand('results/{antibody}/clustering/bam_per_cluster/{sample}/',antibody = antibody, sample = antibody_dict[antibody]) for antibody in antibody_list],
    'results/merged/H3K27me3/bam_per_cluster/',

    # Peak callin bam per cluster
    [expand('results/{antibody}/clustering/bam_per_cluster/macs_broad/{cluster}/{cluster}_peaks.broadPeak',antibody = antibody, \
      cluster=list(set([os.path.basename(x).replace("_out.bam","") for x in glob.glob('results/' + antibody + '/clustering/bam_per_cluster/*/*.bam')]))) for antibody in antibody_list],
    
    # integration
    'results/Olig2/integration/integrated.Rds',
    'results/Rad21/integration/integrated.Rds',
    'results/integration/histone_3active/histone_3active_integrated.Rds',
    'results/integration/H3K4me3_RNA/H3K4me3_RNA_coembed.Rds',
    'results/integration/H3K4me3_marques/H3K4me3_marques_coembed.Rds',

    # GO terms
    'results/H3K4me3/GO_terms/GO_matrix_markers.csv',

    # scATAC
    'results/scATAC_P50/clustering/clustering_scATAC.Rds',

    # Pseudotime
    'results/H3K4me3/pseudotime/pseudotime_OLG_final.Rds',
    'results/H3K4me3/pseudotime/pseudotime_OLG_slingshot.Rds',

    # H3K4me3 spreading
    "results/H3K4me3/spreading/spreading.Rdata",
    "results/H3K4me3/spreading/breadth.Rdata",

    # Olig2 chromvar
    'results/Olig2/chromVAR/chromVAR.Rdata',

    # H3k27ac cicero
    'results/H3K27ac/cicero/cicero_image.Rdata',
    
    # Grosselin
    expand("results/other_datasets/grosselin_scChIP/{SRA}/barcodes/mapping/barcode/{SRA}_read_barcodes.txt",SRA = list(config['grosselin']['scChIP'].keys())),
#    expand("results/other_datasets/grosselin_scChIP/{SRA}/barcodes/mapping/genome/{SRA}.bam",SRA=config['grosselin']['scChIP']),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/macs/{SRA}_peaks.narrowPeak",SRA = list(config['grosselin']['scChIP'].keys())),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/bigwig/{SRA}.bw",SRA = list(config['grosselin']['scChIP'].keys())),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/bowtie2/{SRA}.bw",SRA = list(config['grosselin']['scChIP'].keys())),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/bowtie2/macs/{SRA}_peaks.narrowPeak",SRA = list(config['grosselin']['scChIP'].keys())),
    expand("results/other_datasets/frip_analysis/grosselin/{SRA}/{SRA}_cell_statistics.txt",SRA = list(config['grosselin']['scChIP'].keys())),
    expand("results/other_datasets/grosselin_scChIP/{SRA}/count_matrix/{SRA}_CountTable_hg38.txt.gz",SRA = list(config['grosselin']['scChIP'].keys())),
    
    
    # Kaya-Okur
    expand("results/other_datasets/kaya_okur/bed/sorted_{s}.bed.gz.tbi",s = config['kaya-okur']['samples']),
    expand("results/other_datasets/kaya_okur/bam/{s}.bam",s = config['kaya-okur']['samples']),
    expand("results/other_datasets/kaya_okur/bigwig/{s}.bw",s = config['kaya-okur']['samples']),
    
    # 3T3
    expand("results/other_datasets/3T3_cells/bigwig/{SRA}.bw",SRA = [config['3T3']['samples'][x] for x in ['rep1','rep2']]),
    'results/other_datasets/3T3_cells/macs/3T3_peaks.narrowPeak',
    
    # mESC
    "results/other_datasets/mESC_ENCODE/macs/mESC_peaks.narrowPeak",
     
    # Fingerprint analysis
    "results/other_datasets/fingerprint_analysis/Kaya_okur_fingerprint.txt",
    "results/other_datasets/fingerprint_analysis/Grosselin_fingerprint.txt",
    "results/other_datasets/fingerprint_analysis/scCT_H3K27me3_fingerprint.txt",
    "results/other_datasets/fingerprint_analysis/brain_bulk_fingerprint.txt",
    
    # FrIP analysis
    expand("results/other_datasets/frip_analysis/kaya_okur/{sample}/all_fragments.txt",sample=['K562_H3K27me3_iCell8','K562_H3K4me2_iCell8','H1_H3K27me3_iCell8']),
    expand("results/other_datasets/frip_analysis/scCT/{sample}/all_fragments.txt",antibody="H3K27me3",sample=["H3K27me3_N" + str(x) for x in [1,2,3,4]] + ["H3K27me3_cell_lines_1","H3K27me3_cell_lines_2"]),
    
    # PCA analysis
    'results/other_datasets/PCA/PCA_table_cell_lines.npz',
    'results/other_datasets/PCA/PCA_table_brain.npz',
    
    # Downsample fragments by cells
    expand('results/other_datasets/downsample/bigwig/fragments_{sample}_{n}.bw',sample=['Oli-neu',"3T3","mESC"],n=[10,20,50,100,200,500,1000,2000,5000]),
    expand('results/other_datasets/downsample/bulk_bigwig/{sample}.bw',sample=['3T3','mESC']),
    expand("results/other_datasets/downsample/heatmap/{sample}_{s}_matrix.txt.gz",sample = ['3T3','mESC'], s = ['sc','bulk']),
    expand("results/other_datasets/downsample/heatmap/{sample}_{method}_matrix.png",sample = ['3T3','mESC','Oli-neu'],method=['sc','bulk']),
    
    # Correlation matrix
    expand("results/other_datasets/correlation/{antibody}_correlation_matrix.txt.gz",antibody=["H3K27me3_cell_lines"]),
    
    # Figures
    "results/Figures/revision/cell_lines_genome_browser.pdf",
    "results/Figures/revision/brain_genome_browser.pdf",
    expand("results/Figures/revision/metagene_heatmaps/{sample}_{method}_matrix.pdf",sample = ['3T3','mESC','Oli-neu'],method=['sc','bulk']),
    
    
    # 
    expand('results/merged/{antibody}/downsample/bam/fragments_{cluster}_{n}.bam',cluster=['mOL'],antibody=['H3K27ac'],n=[10,20,50,100,200,500,1000,2000,5000])


# Fingerprint analysis
# Merge per cluster
rule merge_bam_per_cluster:
  input:
    "results/{antibody}/clustering/bam_per_cluster/"
  output:
    directory('results/merged/{antibody}/bam_per_cluster/')
  params:
    bam_per_cluster_dir =  "results/{antibody}/clustering/bam_per_cluster/"
  threads:16
  shell:
    """
    clusters=$(ls {params.bam_per_cluster_dir}/*/*.bam | while read line; do basename $line| sed 's/_out.bam//g'; done | sort | uniq); 
    for cluster in $clusters; do  
      infiles=$(find {params.bam_per_cluster_dir} -name $cluster"*.bam") ; 
      samtools merge -@ {threads} "{output}"$cluster"_merged.bam" $infiles; 
      samtools index {output}
    done
    """

rule plot_heatmap_scCT:
  input:
    merged_bam        = "results/merged/{antibody}/possorted_bam.bam",
    per_replicate_bam = expand("{cellranger}/outs/possorted_bam.bam",cellranger = [config['samples'][x]['cellranger_out'] for x in config['samples'] if config['samples'][x]['Antibody'] == "H3K27me3"]),
    per_cluster_bam   = 'results/merged/{antibody}/bam_per_cluster/',
  output:
    "results/other_datasets/fingerprint_analysis/scCT_{antibody}_fingerprint.txt"
  threads: 16
  params:
    per_cluster_bam = 'results/merged/H3K27me3/bam_per_cluster/*.bam'
  shell:
    """
      plotFingerprint --ignoreDuplicates --outRawCounts {output} -b {input.merged_bam} {input.per_replicate_bam} {params.per_cluster_bam} -p 16
    """

# FrIP analysis

rule call_peaks_scCT_FrIP:
  input:
    #bam="results/{sample}/outs/fragments.tsv.gz" # Cellranger fragments.tsv output
    bam = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam'
  output:
    directory("results/other_datasets/frip_analysis/scCT/{sample}/macs/")
  params:
    outdir = directory("results/other_datasets/frip_analysis/scCT/{sample}/macs/"),
    name   = "{sample}"
  shell:
    "macs2 callpeak -t {input.bam} -g mm -f BAM --outdir {params.outdir} --nomodel -n {params.name} --max-gap 2500 --nolambda --slocal 1000000 --llocal 1000000"

rule intersect_fragments_with_peaks:
  input:
    peaks = "results/other_datasets/frip_analysis/scCT/{sample}/macs/",
    fragments = "results/{sample}/outs/fragments.tsv.gz",
  output:
    all_fragments  = "results/other_datasets/frip_analysis/scCT/{sample}/all_fragments.txt",
    peak_fragments = "results/other_datasets/frip_analysis/scCT/{sample}/peak_fragments.txt",
  params:
      sample = "{sample}"
  shell:
    """
    zcat {input.fragments} | cut -f4 | sort | uniq -c > {output.all_fragments} 
    bedtools intersect -a {input.fragments} -b {input.peaks}{params.sample}_peaks.narrowPeak -wa | cut -f4 | sort | uniq -c > {output.peak_fragments}
    """

rule bed_per_cluster_and_replicate:
  input:
    fragments = "results/merged/{antibody}/fragments.tsv.gz",
    barcodes  = "results/{antibody}/clustering/bam_per_cluster/cluster_barcode_table.csv"
  output:
    directory("results/other_datasets/correlation/{antibody}/bed/")
  params:
    script = os.path.dirname(workflow.basedir) + "/scripts/export_bam_per_replicate_and_cluster.py"
  shell:
    """
    python3 {params.script} -f {input.fragments}  -b {input.barcodes}  -o {output} 
    """

rule bed_to_bam_per_cluster_and_replicate:
  input:
    bed = "results/other_datasets/correlation/{antibody}/bed/",
    genome = "results/mm10.chromSizes",
  output:
    directory("results/other_datasets/correlation/{antibody}/bam/")
  shell:
    """
    ls {input.bed}*.bed | while read line; do 
      BAM=$(basename ${{line/.bed/.bam}})
      bedToBam -i $line -g {input.genome} > {output}$BAM && samtools index {output}$BAM & 
    done
    wait $(jobs -p)
    """

rule bam_to_bw_bam_per_cluster:
  input:
    "results/other_datasets/correlation/{antibody}/bam/"
  output:
    directory("results/other_datasets/correlation/{antibody}/bigwig/")
  threads: 16
  shell:
    """
    ls {input}*.bam | while read line; do
      BIGWIG=$(basename ${{line/.bam/.bw}})
      bamCoverage -b $line -o {output}$BIGWIG --normalizeUsing RPKM -p {threads}
    done
    """

rule bigwig_summary_all_peaks:
  input:
    scCT_bigwig        = "results/other_datasets/correlation/{antibody}/bigwig/",
    peaks              = "results/merged/{antibody}/macs/narrow/{antibody}_peaks.narrowPeak",
  output:
    matrix             = "results/other_datasets/correlation/{antibody}_correlation_matrix.txt.gz"
  threads: 16
  shell:
    "multiBigwigSummary BED-file -b {input.scCT_bigwig}*.bw -o {output.matrix} --BED {input.peaks} -p {threads}"

#######################################################
rule downsample_H3K27ac:
  input:
    fragments = "results/merged/{antibody}/fragments.tsv.gz",
    barcodes  = "results/{antibody}/clustering/bam_per_cluster/cluster_barcode_table.csv",
  params:
    script  = os.path.dirname(workflow.basedir) + "/scripts/downsample_sc.py",
    n       = "{n}"
  output:
    'results/merged/{antibody}/downsample/bed/fragments_{cluster}_{n}.bed'
  shell:
    """
    python3 {params.script} -f {input.fragments} -b {input.barcodes} -n {params.n} -c {wildcards.cluster} -o {output}
    """

rule downscale_general_bed_to_bam:
  input:
    bed = 'results/merged/{antibody}/downsample/bed/fragments_{cluster}_{n}.bed',
    chromSizes = 'results/mm10.chromSizes'
  output:
    bam = 'results/merged/{antibody}/downsample/bam/fragments_{cluster}_{n}.bam'
  shell:
    "bedToBam -i {input.bed} -g {input.chromSizes} > {output.bam} && samtools index {output.bam}"

  


######################################################
rule downscale_prep:
  input:
    fragments = "results/merged/H3K27me3_cell_lines/fragments.tsv.gz",
    barcodes  = "results/H3K27me3_cell_lines/clustering/bam_per_cluster/cluster_barcode_table.csv",
  params:
    cluster = "{sample}",
    script  = os.path.dirname(workflow.basedir) + "/scripts/downsample_sc.py",
    n       = "{n}"
  output:
    'results/other_datasets/downsample/bed/fragments_{sample}_{n}.bed'
  shell:
    """
    python3 {params.script} -f {input.fragments} -b {input.barcodes} -n {params.n} -c {params.cluster} -o {output}
    """

rule fetchChromSizes:
  output:
    'results/mm10.chromSizes'
  shell:
    "fetchChromSizes mm10 > {output}"

rule downscale_bed_to_bam:
  input:
    bed = 'results/other_datasets/downsample/bed/{sample}.bed',
    chromSizes = 'results/mm10.chromSizes'
  output:
    bam = 'results/other_datasets/downsample/bam/{sample}.bam'
  shell:
    "bedToBam -i {input.bed} -g {input.chromSizes} > {output.bam} && samtools index {output.bam}"
  

rule downscale_bam_to_bw:
  input:
    bam = 'results/other_datasets/downsample/bam/{sample}.bam',
  output:
    bw = 'results/other_datasets/downsample/bigwig/{sample}.bw'
  threads: 8
  shell:
    "bamCoverage -b {input.bam} -o {output.bw} --normalizeUsing RPKM -p {threads}"

rule downscale_prep_bulk_bw:
  input:
    bam = lambda wildcards: {"3T3": "results/other_datasets/3T3_cells/possorted_bam/SRR9889940.bam", \
                             "mESC": "results/other_datasets/mESC_ENCODE/bam/mESC_rep1.bam", \
                             "Oli-neu": config['CR_GCB']['Oli-neu']['bam'] }[wildcards.sample.replace("_1","")],
  output:
    bw = 'results/other_datasets/downsample/bulk_bigwig/{sample}.bw'
  threads: 16
  shell:
    "bamCoverage -b {input.bam} -o {output.bw} --normalizeUsing RPKM -p {threads}"

rule compute_matrix:
  input:
    sc    = "results/other_datasets/downsample/bigwig/",
    bulk  = "results/other_datasets/downsample/bulk_bigwig/{sample}.bw",
    peaks = lambda wildcards: {"3T3": "/data/proj/GCB_MB/CT/git_test/results/other_datasets/3T3_cells/macs/3T3_summits.bed", \
                               "mESC": "results/other_datasets/mESC_ENCODE/peaks/ENCFF105NKG.bed", \
                               "Oli-neu": "results/other_datasets/Oli_neu/macs/Oli_neu_summits.bed"}[wildcards.sample]
  output:
    sc_out   = "results/other_datasets/downsample/heatmap/{sample}_sc_matrix.txt.gz",
    bulk_out = "results/other_datasets/downsample/heatmap/{sample}_bulk_matrix.txt.gz",
  params:
  threads: 16
  shell:
    """
    l=$(ls {input.sc}fragments_{wildcards.sample}*.bw | while read line; do basename $line | sed 's/fragments_{wildcards.sample}_//g' | sed 's/.bw//g' ;done | sort -nr)     
    files=$(for i in $l; do ls {input.sc}"fragments_{wildcards.sample}_"$i".bw"; done)                                                                                      # Aim of this is to re-order the files for the heatmap matrix
    computeMatrix reference-point -S $files       -R {input.peaks} -o {output.sc_out}   -a 10000 -b 10000 -p {threads} --missingDataAsZero
    computeMatrix reference-point -S {input.bulk} -R {input.peaks} -o {output.bulk_out} -a 10000 -b 10000 -p {threads} --missingDataAsZero
    """

rule plot_heatmap:
  input:
    matrix   = "results/other_datasets/downsample/heatmap/{sample}_{method}_matrix.txt.gz",
  output:
    png   = "results/other_datasets/downsample/heatmap/{sample}_{method}_matrix.png",
  params:
    zmax = lambda wildcards: {"3T3": {"sc":"100","bulk": "8"}, "mESC": {"sc": "1000","bulk": "8"}, "Oli-neu": {"sc": "100", "bulk": "8"}}[wildcards.sample][wildcards.method]
  shell:
    """
    plotHeatmap -m {input.matrix}   -o {output.png}   --zMax {params.zmax}; 
    """


##################################################

# Motif search
rule motif_search:
  input:
      peaks     = "results/merged/{antibody}/macs/narrow/{antibody}_summits.bed",
      blacklist = "results/mm10.blacklist.bed.gz"
  output:
      meme_out           = directory("results/merged/{antibody}/MEME_{width}/out_{npeaks}"),
  params:
      summits_filtered   = "results/merged/{antibody}/MEME_{width}/summits_filtered_{npeaks}.bed",
      top_summits        = "results/merged/{antibody}/MEME_{width}/top_summits_{npeaks}.bed",
      top_summits_padded = "results/merged/{antibody}/MEME_{width}/top_summits_padded_{npeaks}.bed",
      top_summits_fa     = "results/merged/{antibody}/MEME_{width}/top_summits_{npeaks}.fa",
      genome_fa          = config['db']['genome_fa'],
      npeaks             = "{npeaks}",
      #out                = "results/merged/{antibody}/MEME_{width}/out_{npeaks}",
  shell:
#      "set +o pipefail;"
      "cat {input.peaks} | grep -v -e 'chrM' | sort-bed - | bedops -n 1 - {input.blacklist} > {params.summits_filtered};"
      "sort -k5gr {params.summits_filtered} | head -{params.npeaks} | sort-bed - > {params.top_summits};"
      "bedops --range {wildcards.width} -u {params.top_summits} > {params.top_summits_padded};"
      "bedtools getfasta -fi {params.genome_fa} -bed {params.top_summits_padded} -fo {params.top_summits_fa};"
      "conda activate meme; " # MEME=5.1.1 env
      "meme-chip -oc {output.meme_out} -dreme-m 10 -meme-nmotifs 10 {params.top_summits_fa};"

###########################################################
################### DOWNSTREAM ANALYSIS ###################
###########################################################

rule call_peaks_bam_per_cluster:
  input:
    lambda wildcards: expand('results/{antibody}/clustering/bam_per_cluster/{sample}/',sample = antibody_dict[wildcards.antibody],antibody = wildcards.antibody),
  output:
   'results/{antibody}/clustering/bam_per_cluster/macs_broad/{cluster}/{cluster}_peaks.broadPeak',
  params:
    bam_files = lambda wildcards: expand('results/{antibody}/clustering/bam_per_cluster/{sample}/{cluster}_out.bam',sample = antibody_dict[wildcards.antibody],antibody = wildcards.antibody,cluster = wildcards.cluster),
    outdir    = 'results/{antibody}/clustering/bam_per_cluster/macs_broad/{cluster}'
  shell:
    "macs2 callpeak -t {params.bam_files}  \
  -n {wildcards.cluster} \
  -f BAMPE \
  -g mm \
  --qvalue 1e-10 \
  --outdir {params.outdir} \
  --broad \
  --bdg \
  --max-gap 1000 \
  --min-length 500 \
  --broad-cutoff 0.001 \
  --llocal 1000000 \
  --slocal 0"





rule markers_to_gene:
  input:
    markers  = 'results/{antibody}/clustering/markers.csv'
  output:
    directory('results/{antibody}/clustering/markers_bed_genes/')
  params:
    script = os.path.dirname(workflow.basedir) + "/scripts/R/markers_to_bed.R"
  shell:
    "Rscript {params.script} {input.markers} {output}"


######## METAGENE PLOTS
rule metagene:
  input:
    bw       = "results/{antibody1}/clustering/bigwig/",
    bed      = "results/{antibody2}/clustering/markers_bed/",
    bed_gene = "results/{antibody2}/clustering/markers_bed_genes/",
  output:
    matrix1 = "results/{antibody1}/metagene/{antibody2}/metagene_plot.txt.gz",
    png1    = "results/{antibody1}/metagene/{antibody2}/metagene_plot.png",
    matrix2 = "results/{antibody1}/metagene/{antibody2}/metagene_genes.txt.gz",
    png2    = "results/{antibody1}/metagene/{antibody2}/metagene_genes.png",
  threads: 8
  shell:
    "computeMatrix reference-point -S {input.bw}*.bw -R {input.bed}*.bed -o {output.matrix1} -a 10000 -b 10000 -p {threads} &&"
    "plotHeatmap -m {output.matrix1} -o {output.png1} --sortRegions descend --refPointLabel peak --averageTypeSummaryPlot sum --colorList white,darkred --heatmapWidth 10  --heatmapHeight 80; "
    
    "computeMatrix scale-regions -S {input.bw}*.bw -R {input.bed_gene}*.bed -o {output.matrix2} -a 2000 -b 2000 -p {threads} &&"
    "plotHeatmap -m {output.matrix2} -o {output.png2} --sortRegions descend --refPointLabel peak --averageTypeSummaryPlot sum --colorList white,darkred --heatmapWidth 10  --heatmapHeight 80; "



rule metagene_RNA_promoters:
  input:
    promoters  = 'results/{RNA}/marker_promoters/',
    bigwig     = 'results/{antibody}/clustering/bigwig/',
  output:
    matrix   = 'results/{antibody}/metagene/metagene_{RNA}_promoters.txt.gz',
    png      = 'results/{antibody}/metagene/metagene_{RNA}_promoters.png',
    matrix2  = 'results/{antibody}/metagene/metagene_{RNA}_genes_scaled.txt.gz',
    png2     = 'results/{antibody}/metagene/metagene_{RNA}_genes_scaled.png',
  threads: 8
  shell:
    "computeMatrix reference-point -S {input.bigwig}*.bw -R {input.promoters}*_promoters.bed -o {output.matrix} -a 10000 -b 10000 -p {threads} && "
    "plotHeatmap -m {output.matrix} -o {output.png} --sortRegions descend --refPointLabel promoter --averageTypeSummaryPlot sum --colorList white,darkgreen --heatmapWidth 10  --heatmapHeight 80; "
    "computeMatrix scale-regions -S {input.bigwig}*.bw -R {input.promoters}*_genes.bed -o {output.matrix2} -a 2000 -b 2000 -p {threads} && "
    "plotHeatmap -m {output.matrix2} -o {output.png2} --sortRegions descend --refPointLabel promoter --averageTypeSummaryPlot sum --colorList white,darkgreen --heatmapWidth 10  --heatmapHeight 80; "

rule export_bam_per_cluster: 
  input:
    bam   = lambda wildcards: config['samples'][wildcards.sample]['cellranger_out'] + '/outs/possorted_bam.bam',
    table = 'results/{antibody}/clustering/bam_per_cluster/cluster_barcode_table.csv',
  output:
    sam_files  = directory('results/{antibody}/clustering/bam_per_cluster/{sample}/'),
  params:
    filter_bam          =   os.path.dirname(workflow.basedir) + "/scripts/filter_bam_by_barcode.py",
    sample              =   lambda wildcards: wildcards.sample,
  shell:
    "python3 {params.filter_bam} {input.bam} {input.table} {params.sample} {output.sam_files}; "

###### H3K4me3 GO analysis
rule GO_H3K4me3:
  input:
    seurat  = "results/H3K4me3/clustering/01.clustering.Rds",
    markers = "results/H3K4me3/clustering/markers.csv",
  output:
    'results/H3K4me3/GO_terms/GO_matrix_markers.csv',
  params:
    notebook   = os.path.dirname(workflow.basedir) + "/notebooks/H3K4me3/GO_analysis.Rmd",
    report     = CWD + '/results/H3K4me3/GO_terms/GO_analysis.html',
    out_prefix = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{params.notebook}',output_file='{params.report}',params=list(out_prefix='{params.out_prefix}')) \""


###### H3K4me3 pseudotime
rule pseudotime:
  input:
    seurat   = 'results/H3K4me3/clustering/01.clustering.Rds',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/H3K4me3/pseudotime.Rmd',
  output:
    'results/H3K4me3/pseudotime/pseudotime_OLG_final.Rds',
    'results/H3K4me3/pseudotime/pseudotime_OLG_slingshot.Rds'
  params:
    out_prefix = CWD + '/results/',
    report     = CWD + '/results/H3K4me3/pseudotime/pseudotime_final.html',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""


######### H3K4me3 spreading

rule spreading_H3K4me3:
  input:
    "results/H3K4me3/clustering/01.clustering.Rds",
    "results/H3K4me3/pseudotime/pseudotime_OLG_final.Rds",
    "results/H3K4me3/pseudotime/pseudotime_OLG_slingshot.Rds",
    "results/merged/H3K4me3/fragments.tsv.gz",
    "results/Sox10_RNA/clustering/GFP/markers.csv",
    "results/merged/H3K4me3/macs/broad/H3K4me3_peaks.broadPeak",
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/H3K4me3/spreading.Rmd',
  output:
    "results/H3K4me3/spreading/spreading.Rdata",
  params:
    out_prefix = CWD + "/results/",
    report     = CWD + "/results/H3K4me3/spreading/spreading.html",
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""

rule breadth_H3K4me3:
  input:
    # Cellranger peaks.bed file
    lambda wildcards: ['results/' + x + '/outs/fragments.tsv.gz' for x in antibody_dict[wildcards.antibody] ],
    'results/Sox10_RNA/clustering/GFP/markers.csv',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/H3K4me3/breadth.Rmd',
  output:
    "results/{antibody}/spreading/breadth.Rdata",
  params:
    report = CWD + "/results/{antibody}/spreading/breadth.html",
    out_prefix = CWD + '/results/'
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""    


# Olig2 chromvar
rule chromvar:
  input:
    'results/{antibody}/clustering/01.clustering.Rds',
    'results/merged/{antibody}/fragments.tsv.gz',
    'results/merged/{antibody}/macs/narrow/{antibody}_summits.bed',
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/{antibody}/chromVAR.Rmd',
  output:
    'results/{antibody}/chromVAR/chromVAR.Rdata',
  params:
    report      = CWD + '/results/{antibody}/chromVAR/chromVAR.html',
    out_prefix  = CWD + '/results/',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""    


# H3K27ac cicero

rule cicero:
  input:
    'results/{antibody}/clustering/01.clustering.Rds',
#    directory('results/{antibody}/clustering/bam_per_cluster/H3K27ac_N1/'), # Fix this ?
#    directory('results/{antibody}/clustering/bam_per_cluster/H3K27ac_N2/'), # Fix this ?
    notebook = os.path.dirname(workflow.basedir) + '/notebooks/{antibody}/Cicero.Rmd',
  output:
    'results/{antibody}/cicero/cicero_image.Rdata',
    directory('results/{antibody}/cicero/loops/')
  params:
    report      = CWD + '/results/{antibody}/cicero/cicero.html',
    out_prefix  = CWD + '/results/',
  shell:
    "Rscript -e \"rmarkdown::render(input='{input.notebook}',output_file = '{params.report}', params=list(out_prefix = '{params.out_prefix}'))\""    



# TODO rule H3K4me3 integaration with marques RNA 

















